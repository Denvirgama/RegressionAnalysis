---
title: "DSC423_Project_FB"
team: "DATA CREW"
author: "JITEN MISHRA"
date: "2023-02-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r Imports , message=FALSE}
library(psych)
library(corrplot)
library(QuantPsyc)
library(car)
```

```{r Project }
# read the csv file
myd <- read.csv("dataset_Facebook.csv",sep = ";", header = T)

# Column reference 
# PTLike <- Page total likes
# Type
# Category (1,2,3 - product / action / inspiration)
# PosMon <- Post Month
# PosWkDay <- Post Weekday
# PosHr <- Post Hour
# Paid
# LPTReach <- Lifetime Post Total Reach
# LPTImpr <- Lifetime Post Total Impressions 
# LEngUser <- Lifetime Engaged Users
# LPConsumer <- Lifetime Post Consumers
# LPConsump <- Lifetime Post Consumption
# LPIPepLkPage <- Lifetime Post Impressions by people who have liked your Page
# LPRchPepLKPage <- Lifetime Post reach by people who like your Page
# LPepLkEngPos <- Lifetime People who have liked your Page and engaged with your post
# comment
# like
# share
# TotalInterac <- Total Interactions 

colnames(myd) <- c('PTLike','Type','Category','PosMon','PosWkDay','PosHr','Paid','LPTReach','LPTImpr','LEngUser','LPConsumer','LPConsump','LPIPepLkPage','LPRchPepLKPage','LPepLkEngPos','comment','like','share','TotalInterac')

myd <- na.omit(myd)

# removing features used for evaluating post impact
# and other not required variables
#myd <- myd[,-c(8:15)]
myd <- myd[,-c(8:10)]
myd <- myd[,-c(9:12)]
myd <- myd[,-c(9:11)]

attach(myd)
# create dummy variables
# Type (Photos,Status,Video,Link)
# category Factor: {action, product, inspiration }
myd$typeP=(Type=="Photo")*1
myd$typeS=(Type=="Status")*1
myd$typeV=(Type=="Video")*1
myd$category1=(Category==1)*1
myd$category2=(Category==2)*1
detach(myd)

# remove the column for which we created dummy variables
# also removing comment,like,share since we have total interaction
mydata <- myd[,-c(2:3)]

# describe the distribution of Life Time post consumers
describe(mydata$LPConsumer)

# summary of  life time post consumers
summary(mydata$LPConsumer)


# plot a histogram on the Y variable
hist(mydata$LPConsumer,probability = TRUE ,xlab = "Life Time Post Comsumer",main="Histogram")

# since the histogram looks exponential we try log of Y variable
hist(log(mydata$LPConsumer),probability = TRUE ,xlab = "Life Time Post Comsumer",main="Histogram")

# scatter plots for life time post consumers vs independent variables
plot(mydata$PTLike,log(mydata$LPConsumer), xlab = "Page Total Likes", ylab = "Life Time Post Consumer", main = "Scatterplot Life Time post Consumer vs Page Total Likes")
abline(lm(log(mydata$LPConsumer)~mydata$PTLike), col="red")

# boxplot of the qualitative variables with response variable
boxplot(log(mydata$LPConsumer) ~ mydata$Paid, xlab = 'Paid', ylab = 'Log LPConsumer' )
boxplot(log(mydata$LPConsumer) ~ mydata$PosHr, xlab = 'Post Hour', ylab = 'Log LPConsumer')
boxplot(log(mydata$LPConsumer) ~ mydata$PosMon, xlab = 'Post Month', ylab = 'Log LPConsumer')
boxplot(log(mydata$LPConsumer) ~ mydata$PosWkDay, xlab = 'Post Weekday', ylab = 'Log LPConsumer')


# correlation of the dataset
mydata_cor <- cor(mydata, method = "pearson")
corrplot(mydata_cor,type="lower", method = 'number', addCoef.col = 'brown',
         number.cex = 0.5, tl.cex = 0.7)

# model including all relevant variables 
fit_full_1 <- lm(log(LPConsumer) ~ PTLike + PosHr + Paid + TotalInterac + typeP + typeS +
                   typeV + category1 + category2, data=mydata)
summary(fit_full_1) # show results


# from the above model we see PosHr and catergory2 are not significant hence we removed them 
fit_full_2 <- lm(log(LPConsumer) ~ PTLike + Paid + TotalInterac + typeP + typeS +
                   typeV + category1 , data=mydata)
summary(fit_full_2) # show results

# stepwise variable selection on the full result also gave same result 
step(fit_full_1, direction = "backward", trace = FALSE)

# check multicollinearity
vif(fit_full_2)

# analysis of variance
anova(fit_full_2)

# influential measures 
# influence.measures(fit_full_2)

# 95% confidence interval of the fitted model
confint(fit_full_2, level=0.95)

# influential Plot
influencePlot(fit_full_2)

# removing influential point 241
fit_influence <- lm(log(LPConsumer) ~ PTLike + Paid + TotalInterac + typeP + typeS +
                   typeV + category1 ,data=mydata[-241,])
summary(fit_influence)

# standardized beta coefficient 
lm.beta(fit_influence)


# studentized vs predicted
plot(rstandard(fit_influence) ~ fitted(fit_influence))
abline(a=0,b=0,col='red')

# normal probability plot
qqnorm(rstandard(fit_influence))
qqline(rstandard(fit_influence), col = 2)

### 
# model interaction of Paid with other independent variables
fit_full_3 <- lm(log(LPConsumer) ~ Paid*( PTLike  + typeP + typeS + TotalInterac +
                   typeV + category1) , data=mydata)
summary(fit_full_3) # show results

# stepwise variable selection on the full interaction model
step(fit_full_3, direction = "backward", trace = FALSE)

# selecting the model from stepwise backward variable selection process
fit_full_4 <- lm(formula = log(LPConsumer) ~ Paid + PTLike + typeP + typeS + 
                TotalInterac + typeV + category1 + Paid:TotalInterac, data = mydata)
summary(fit_full_4)

# check multicolinearity
vif(fit_full_4)

# influential Plot
influencePlot(fit_full_4)

# removing influential point 241
fit_influence2 <- lm(formula = log(LPConsumer) ~ Paid + PTLike + typeP + typeS + 
                TotalInterac + typeV + category1 + Paid:TotalInterac ,data=mydata[-241,])
summary(fit_influence2)

# studentized vs predicted
plot(rstandard(fit_full_4) ~ fitted(fit_full_4))
abline(a=0,b=0,col='red')

# normal probability plot
qqnorm(rstandard(fit_full_4))
qqline(rstandard(fit_full_4), col = 2)

# 95% confidence interval of the fitted model
confint(fit_full_4, level=0.95)

#
#
#
# full interaction model
fit_full_5 <- lm(log(LPConsumer) ~ ( PTLike + Paid + typeP + typeS + TotalInterac +
                   typeV + category1)^2 , data=mydata)
summary(fit_full_5) # show results

# stepwise variable selection on the full interaction model
step(fit_full_5, direction = "backward" , trace = FALSE)

# taking model given by stepwise
fit_full_6 <- lm(log(LPConsumer) ~ PTLike + Paid + typeP + typeS + TotalInterac + 
    typeV + category1 + PTLike:typeP + Paid:typeP + Paid:TotalInterac + 
    Paid:category1 + typeP:TotalInterac + typeS:TotalInterac + 
    TotalInterac:typeV + TotalInterac:category1, data = mydata)

summary(fit_full_6)

# check multicolinearity
vif(fit_full_6)

# removing multicoliniearity typeP:TotalInterac
fit_full_7 <- lm(log(LPConsumer) ~ PTLike + Paid + typeP + typeS + TotalInterac + 
    typeV + category1 + PTLike:typeP + Paid:typeP + Paid:TotalInterac + 
    Paid:category1 + typeS:TotalInterac + 
    TotalInterac:typeV + TotalInterac:category1, data = mydata)

# summary of the model
summary(fit_full_7)

# checking multicolinearity again
vif(fit_full_7)

# removing multicolinearity PTLike:typeP 
fit_full_8 <- lm(log(LPConsumer) ~ PTLike + Paid + typeP + typeS + TotalInterac + 
    typeV + category1 + Paid:typeP + Paid:TotalInterac + 
    Paid:category1 + typeS:TotalInterac + 
    TotalInterac:typeV + TotalInterac:category1, data = mydata)

summary(fit_full_8)

# removing Paid:category1 TotalInterac:typeV which are not significant
# cant remove variables which are part of interactions
#
fit_full_10 <- lm(log(LPConsumer) ~ PTLike + Paid + typeP + typeS + TotalInterac + 
    typeV + category1  + Paid:typeP + Paid:TotalInterac + 
     typeS:TotalInterac + TotalInterac:category1, data = mydata)

# summary of the model
summary(fit_full_10)

# checking multicolinearity again
vif(fit_full_10)

# 95% confidence interval of the fitted model
confint(fit_full_10, level=0.95)

# studentized vs predicted
plot(rstandard(fit_full_10) ~ fitted(fit_full_10))
abline(a=0,b=0,col='red')

# normal probability plot
qqnorm(rstandard(fit_full_10))
qqline(rstandard(fit_full_10), col = 2)



# model validation
# setting the seed to get the same result when knit
set.seed(2500)

# split samples (75% for training and 25% for testing)
select.mydata<-sample(1:nrow(mydata), 0.75*nrow(mydata))

#Selecting 75% of the data for training purpose
train.mydata<-mydata[select.mydata,]

#Selecting 25% (remaining) of the data for testing
test.mydata<-mydata[-select.mydata,]

# Model: 1 : fit_full_2
fit_m1_trn <- lm(log(LPConsumer) ~ PTLike + Paid + TotalInterac + typeP + typeS +
                   typeV + category1, data = train.mydata)

# summary of fit_m1
summary(fit_m1_trn)

# create fitted values using test.mydata
y_pred <- predict.glm(fit_m1_trn,test.mydata)
y_obs <- log(test.mydata[,"LPConsumer"])

# validation statistics
# RMSE of prediction error
rmse_m1 <-sqrt((y_obs-y_pred)%*%(y_obs-y_pred)/nrow(test.mydata))
rmse_m1
#0.5815742

# compute MAE
mae_m1<-mean(abs(y_obs-y_pred))
mae_m1
#0.418022

# compute MAPE
mape_m1<-mean(abs((y_obs-y_pred)/y_obs))*100
mape_m1
#6.76256

# compute cross-validated R^2_pred
r2_pred = cor(cbind(y_obs,y_pred))**2
r2_train = summary(fit_m1_trn)$r.squared
diffr2_m1=abs(r2_train-r2_pred)
#print difference of cross-validate R2 and R2
diffr2_m1[1,2]
#0.01478991

# Model: 2 : fit_full_4
fit_int_m1_trn <- lm(formula = log(LPConsumer) ~ Paid + PTLike + typeP + typeS + 
                TotalInterac + typeV + category1 + Paid:TotalInterac, data = train.mydata)

# summary of fit_m1
summary(fit_int_m1_trn)

# create fitted values using test.mydata
y_pred2 <- predict.glm(fit_int_m1_trn,test.mydata)
y_obs2 <- log(test.mydata[,"LPConsumer"])

# validation statistics
# RMSE of prediction error
rmse_m1_2 <-sqrt((y_obs2-y_pred2)%*%(y_obs2-y_pred2)/nrow(test.mydata))
rmse_m1_2
#0.55563

# compute MAE
mae_m1_2<-mean(abs(y_obs2-y_pred2))
mae_m1_2
#0.4020156

# compute MAPE
mape_m1_2<-mean(abs((y_obs2-y_pred2)/y_obs2))*100
mape_m1_2
#6.479455

# compute cross-validated R^2_pred
r2_pred2 = cor(cbind(y_obs2,y_pred2))**2
r2_train2 = summary(fit_int_m1_trn)$r.squared
diffr2_m1_2=abs(r2_train2-r2_pred2)
#print difference of cross-validate R2 and R2
diffr2_m1_2[1,2]
#0.001601767


# Model 3 : fit_full_10
fit_int_m2_trn <- lm(log(LPConsumer) ~ PTLike + Paid + typeP + typeS + TotalInterac + 
    typeV + category1  + Paid:typeP + Paid:TotalInterac + 
     typeS:TotalInterac + TotalInterac:category1, data = train.mydata)

# summary of fit_m1
summary(fit_int_m2_trn)

# create fitted values using test.mydata
y_pred3 <- predict.glm(fit_int_m2_trn,test.mydata)
y_obs3 <- log(test.mydata[,"LPConsumer"])

# validation statistics
# RMSE of prediction error
rmse_m3 <-sqrt((y_obs3-y_pred3)%*%(y_obs3-y_pred3)/nrow(test.mydata))
rmse_m3
#0.5427854

# compute MAE
mae_m3<-mean(abs(y_obs3-y_pred3))
mae_m3
#0.3896497

# compute MAPE
mape_m3<-mean(abs((y_obs3-y_pred3)/y_obs3))*100
mape_m3
#6.345567

# compute cross-validated R^2_pred
r2_pred3 = cor(cbind(y_obs3,y_pred3))**2
r2_train3 = summary(fit_int_m2_trn)$r.squared
diffr2_m3=abs(r2_train3-r2_pred3)
#print difference of cross-validate R2 and R2
diffr2_m3[1,2]
#0.02729964

# create the matrics for comparison
m1 = matrix(c(rmse_m1, rmse_m1_2, rmse_m3, mae_m1, mae_m1_2, mae_m3, mape_m1, mape_m1_2, mape_m3),
            nrow = 3)
colnames(m1) <- c('RMSE', 'MAE', 'MAPE')
rownames(m1) <- c('Model 1', 'Model 2', 'Model 3')
#display the matrics
m1

#             RMSE       MAE     MAPE
# Model 1 0.5815742 0.4180220 6.762560
# Model 2 0.5556300 0.4020156 6.479455
# Model 3 0.5427854 0.3896497 6.345567

#Model 3 (fit_full_10) minimizes all three validation matrics and we can conclude that it provides more accurate prediction which is closer to actual values






```
su

